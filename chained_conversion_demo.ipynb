{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chained HDF4 → HDF5 → Text Conversion Demo\n",
    "\n",
    "This notebook demonstrates how to chain together the HDF4 to HDF5 and HDF5 to text conversions in a single operation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from calipso_tool.converter import h4_to_h5, h5_to_txt, h4_to_txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method 1: Using the Chained Function\n",
    "\n",
    "The easiest way is to use the `h4_to_txt` function that handles both conversions automatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input file found: CAL_LID_L3_Tropospheric_APro_AllSky-Standard-V4-20.2018-12D.hdf\n"
     ]
    }
   ],
   "source": [
    "# Define input HDF4 file\n",
    "hdf4_file = Path(\"CAL_LID_L3_Tropospheric_APro_AllSky-Standard-V4-20.2018-12D.hdf\")\n",
    "\n",
    "# Check if file exists\n",
    "if hdf4_file.exists():\n",
    "    print(f\"Input file found: {hdf4_file}\")\n",
    "else:\n",
    "    print(f\"Input file not found: {hdf4_file}\")\n",
    "    print(\"Please ensure the HDF4 file is in the current directory\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1: Converting HDF4 to HDF5...\n",
      "  ✓ Created: CAL_LID_L3_Tropospheric_APro_AllSky-Standard-V4-20.2018-12D.h5\n",
      "\n",
      "Step 2: Converting HDF5 to text...\n",
      "Converted CAL_LID_L3_Tropospheric_APro_AllSky-Standard-V4-20.2018-12D.h5 to CAL_LID_L3_Tropospheric_APro_AllSky-Standard-V4-20.2018-12D.txt\n",
      "Output contains 1272960 points\n",
      "  ✓ Created: CAL_LID_L3_Tropospheric_APro_AllSky-Standard-V4-20.2018-12D.txt\n",
      "\n",
      "Conversion complete!\n",
      "Text file: CAL_LID_L3_Tropospheric_APro_AllSky-Standard-V4-20.2018-12D.txt\n",
      "HDF5 file: CAL_LID_L3_Tropospheric_APro_AllSky-Standard-V4-20.2018-12D.h5\n"
     ]
    }
   ],
   "source": [
    "# Perform chained conversion\n",
    "# Note: You need to update 'variable_name' with the actual variable from your HDF file\n",
    "variable_to_extract = \"Extinction_Coefficient_532_Mean\"  # UPDATE THIS!\n",
    "\n",
    "try:\n",
    "    # Convert HDF4 → HDF5 → Text in one call\n",
    "    txt_file, h5_file = h4_to_txt(\n",
    "        input_h4=hdf4_file,\n",
    "        variable_name=variable_to_extract,\n",
    "        altitude_units=\"km\",  # Will convert to meters\n",
    "        keep_h5=True  # Keep intermediate HDF5 file\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nConversion complete!\")\n",
    "    print(f\"Text file: {txt_file}\")\n",
    "    print(f\"HDF5 file: {h5_file}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"\\nConversion failed: {e}\")\n",
    "    print(\"Make sure to update 'variable_to_extract' with the correct variable name\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method 2: Manual Step-by-Step Conversion\n",
    "\n",
    "You can also perform the conversions separately for more control."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1: Converting HDF4 to HDF5...\n",
      "✓ Created: CAL_LID_L3_Tropospheric_APro_AllSky-Standard-V4-20.2018-12D.h5\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Convert HDF4 to HDF5\n",
    "h5_output = hdf4_file.with_suffix('.h5')\n",
    "\n",
    "try:\n",
    "    print(\"Step 1: Converting HDF4 to HDF5...\")\n",
    "    h4_to_h5(hdf4_file, h5_output)\n",
    "    print(f\"✓ Created: {h5_output}\")\n",
    "except Exception as e:\n",
    "    print(f\"✗ HDF4 to HDF5 conversion failed: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 2: Converting HDF5 to text...\n",
      "Converted CAL_LID_L3_Tropospheric_APro_AllSky-Standard-V4-20.2018-12D.h5 to CAL_LID_L3_Tropospheric_APro_AllSky-Standard-V4-20.2018-12D.txt\n",
      "Output contains 1272960 points\n",
      "✓ Created: CAL_LID_L3_Tropospheric_APro_AllSky-Standard-V4-20.2018-12D.txt\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Convert HDF5 to Text\n",
    "txt_output = hdf4_file.with_suffix('.txt')\n",
    "\n",
    "try:\n",
    "    print(\"Step 2: Converting HDF5 to text...\")\n",
    "    h5_to_txt(\n",
    "        input_h5=h5_output,\n",
    "        output_txt=txt_output,\n",
    "        variable_name=variable_to_extract,\n",
    "        altitude_units=\"km\"\n",
    "    )\n",
    "    print(f\"✓ Created: {txt_output}\")\n",
    "except Exception as e:\n",
    "    print(f\"✗ HDF5 to text conversion failed: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method 3: Using a Pipeline Function\n",
    "\n",
    "You can create your own pipeline function for custom processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting HDF4 to HDF5...\n",
      "Converting HDF5 to text...\n",
      "Converted CAL_LID_L3_Tropospheric_APro_AllSky-Standard-V4-20.2018-12D.h5 to CAL_LID_L3_Tropospheric_APro_AllSky-Standard-V4-20.2018-12D.txt\n",
      "Output contains 1272960 points\n",
      "\n",
      "Loading text data...\n",
      "\n",
      "Data summary:\n",
      "- Total points: 1,272,960\n",
      "- Columns: ['X', 'Y', 'Z', 'Extinction_Coefficient_532_Mean']\n",
      "\n",
      "Statistics:\n",
      "                  X             Y             Z  \\\n",
      "count  1.272960e+06  1.272960e+06  1.272960e+06   \n",
      "mean   0.000000e+00  0.000000e+00  5.820000e+03   \n",
      "std    1.039131e+02  4.907140e+01  3.596852e+03   \n",
      "min   -1.775000e+02 -8.400000e+01 -3.800481e+02   \n",
      "25%   -8.875000e+01 -4.200000e+01  2.719976e+03   \n",
      "50%    0.000000e+00  0.000000e+00  5.820000e+03   \n",
      "75%    8.875000e+01  4.200000e+01  8.920025e+03   \n",
      "max    1.775000e+02  8.400000e+01  1.202005e+04   \n",
      "\n",
      "       Extinction_Coefficient_532_Mean  \n",
      "count                     1.272960e+06  \n",
      "mean                     -1.901435e+03  \n",
      "std                       3.923909e+03  \n",
      "min                      -9.999000e+03  \n",
      "25%                       0.000000e+00  \n",
      "50%                       0.000000e+00  \n",
      "75%                       0.000000e+00  \n",
      "max                       5.219572e+00  \n"
     ]
    }
   ],
   "source": [
    "def convert_calipso_pipeline(hdf4_path, variable_name, cleanup=False):\n",
    "    \"\"\"\n",
    "    Complete pipeline: HDF4 → HDF5 → Text → Analysis\n",
    "    \"\"\"\n",
    "    hdf4_path = Path(hdf4_path)\n",
    "    \n",
    "    # Define output paths\n",
    "    h5_path = hdf4_path.with_suffix('.h5')\n",
    "    txt_path = hdf4_path.with_suffix('.txt')\n",
    "    \n",
    "    # Step 1: HDF4 to HDF5\n",
    "    print(\"Converting HDF4 to HDF5...\")\n",
    "    h4_to_h5(hdf4_path, h5_path)\n",
    "    \n",
    "    # Step 2: HDF5 to Text\n",
    "    print(\"Converting HDF5 to text...\")\n",
    "    h5_to_txt(h5_path, txt_path, variable_name)\n",
    "    \n",
    "    # Step 3: Load and analyze\n",
    "    print(\"\\nLoading text data...\")\n",
    "    df = pd.read_csv(txt_path, sep=' ')\n",
    "    \n",
    "    print(f\"\\nData summary:\")\n",
    "    print(f\"- Total points: {len(df):,}\")\n",
    "    print(f\"- Columns: {list(df.columns)}\")\n",
    "    print(f\"\\nStatistics:\")\n",
    "    print(df.describe())\n",
    "    \n",
    "    # Cleanup if requested\n",
    "    if cleanup:\n",
    "        h5_path.unlink()\n",
    "        print(f\"\\nCleaned up intermediate file: {h5_path}\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Example usage (uncomment to run)\n",
    "df = convert_calipso_pipeline(hdf4_file, variable_to_extract, cleanup=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced: Batch Processing\n",
    "\n",
    "Process multiple CALIPSO files in a directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 9 HDF4 files to process\n",
      "Step 1: Converting HDF4 to HDF5...Step 1: Converting HDF4 to HDF5...Step 1: Converting HDF4 to HDF5...\n",
      "\n",
      "Step 1: Converting HDF4 to HDF5...\n",
      "\n",
      "  ✓ Created: CAL_LID_L3_Tropospheric_APro_AllSky-Standard-V4-20.2018-12D.h5\n",
      "\n",
      "Step 2: Converting HDF5 to text...\n",
      "  ✓ Created: CAL_LID_L3_Tropospheric_APro_AllSky-Standard-V4-20.2019-03D.h5\n",
      "\n",
      "Step 2: Converting HDF5 to text...\n",
      "  ✓ Created: CAL_LID_L3_Tropospheric_APro_AllSky-Standard-V4-20.2019-02D.h5\n",
      "\n",
      "Step 2: Converting HDF5 to text...\n",
      "  ✓ Created: CAL_LID_L3_Tropospheric_APro_AllSky-Standard-V4-20.2019-01N.h5\n",
      "\n",
      "Step 2: Converting HDF5 to text...\n",
      "Converted CAL_LID_L3_Tropospheric_APro_AllSky-Standard-V4-20.2018-12D.h5 to CAL_LID_L3_Tropospheric_APro_AllSky-Standard-V4-20.2018-12D.txt\n",
      "Output contains 1272960 points\n",
      "  ✓ Created: CAL_LID_L3_Tropospheric_APro_AllSky-Standard-V4-20.2018-12D.txt\n",
      "Step 1: Converting HDF4 to HDF5...\n",
      "✓ Converted: CAL_LID_L3_Tropospheric_APro_AllSky-Standard-V4-20.2018-12D.hdf\n",
      "Converted CAL_LID_L3_Tropospheric_APro_AllSky-Standard-V4-20.2019-02D.h5 to CAL_LID_L3_Tropospheric_APro_AllSky-Standard-V4-20.2019-02D.txt\n",
      "Output contains 1272960 points\n",
      "  ✓ Created: CAL_LID_L3_Tropospheric_APro_AllSky-Standard-V4-20.2019-02D.txt\n",
      "Step 1: Converting HDF4 to HDF5...\n",
      "✓ Converted: CAL_LID_L3_Tropospheric_APro_AllSky-Standard-V4-20.2019-02D.hdf\n",
      "Converted CAL_LID_L3_Tropospheric_APro_AllSky-Standard-V4-20.2019-03D.h5 to CAL_LID_L3_Tropospheric_APro_AllSky-Standard-V4-20.2019-03D.txt\n",
      "Output contains 1272960 points\n",
      "  ✓ Created: CAL_LID_L3_Tropospheric_APro_AllSky-Standard-V4-20.2019-03D.txt\n",
      "Step 1: Converting HDF4 to HDF5...\n",
      "✓ Converted: CAL_LID_L3_Tropospheric_APro_AllSky-Standard-V4-20.2019-03D.hdf\n",
      "Converted CAL_LID_L3_Tropospheric_APro_AllSky-Standard-V4-20.2019-01N.h5 to CAL_LID_L3_Tropospheric_APro_AllSky-Standard-V4-20.2019-01N.txt\n",
      "Output contains 1272960 points\n",
      "  ✓ Created: CAL_LID_L3_Tropospheric_APro_AllSky-Standard-V4-20.2019-01N.txt\n",
      "Step 1: Converting HDF4 to HDF5...\n",
      "✓ Converted: CAL_LID_L3_Tropospheric_APro_AllSky-Standard-V4-20.2019-01N.hdf\n",
      "  ✓ Created: CAL_LID_L3_Tropospheric_APro_AllSky-Standard-V4-20.2018-12N.h5\n",
      "\n",
      "Step 2: Converting HDF5 to text...\n",
      "  ✓ Created: CAL_LID_L3_Tropospheric_APro_AllSky-Standard-V4-20.2019-01D.h5\n",
      "\n",
      "Step 2: Converting HDF5 to text...\n",
      "  ✓ Created: CAL_LID_L3_Tropospheric_APro_AllSky-Standard-V4-20.2019-04N.h5\n",
      "\n",
      "Step 2: Converting HDF5 to text...\n",
      "  ✓ Created: CAL_LID_L3_Tropospheric_APro_AllSky-Standard-V4-20.2019-03N.h5\n",
      "\n",
      "Step 2: Converting HDF5 to text...\n",
      "Converted CAL_LID_L3_Tropospheric_APro_AllSky-Standard-V4-20.2018-12N.h5 to CAL_LID_L3_Tropospheric_APro_AllSky-Standard-V4-20.2018-12N.txt\n",
      "Output contains 1272960 points\n",
      "  ✓ Created: CAL_LID_L3_Tropospheric_APro_AllSky-Standard-V4-20.2018-12N.txt\n",
      "Step 1: Converting HDF4 to HDF5...\n",
      "✓ Converted: CAL_LID_L3_Tropospheric_APro_AllSky-Standard-V4-20.2018-12N.hdf\n",
      "Converted CAL_LID_L3_Tropospheric_APro_AllSky-Standard-V4-20.2019-01D.h5 to CAL_LID_L3_Tropospheric_APro_AllSky-Standard-V4-20.2019-01D.txt\n",
      "Output contains 1272960 points\n",
      "  ✓ Created: CAL_LID_L3_Tropospheric_APro_AllSky-Standard-V4-20.2019-01D.txt\n",
      "✓ Converted: CAL_LID_L3_Tropospheric_APro_AllSky-Standard-V4-20.2019-01D.hdf\n",
      "Converted CAL_LID_L3_Tropospheric_APro_AllSky-Standard-V4-20.2019-04N.h5 to CAL_LID_L3_Tropospheric_APro_AllSky-Standard-V4-20.2019-04N.txt\n",
      "Output contains 1272960 points\n",
      "  ✓ Created: CAL_LID_L3_Tropospheric_APro_AllSky-Standard-V4-20.2019-04N.txt\n",
      "✓ Converted: CAL_LID_L3_Tropospheric_APro_AllSky-Standard-V4-20.2019-04N.hdf\n",
      "Converted CAL_LID_L3_Tropospheric_APro_AllSky-Standard-V4-20.2019-03N.h5 to CAL_LID_L3_Tropospheric_APro_AllSky-Standard-V4-20.2019-03N.txt\n",
      "Output contains 1272960 points\n",
      "  ✓ Created: CAL_LID_L3_Tropospheric_APro_AllSky-Standard-V4-20.2019-03N.txt\n",
      "✓ Converted: CAL_LID_L3_Tropospheric_APro_AllSky-Standard-V4-20.2019-03N.hdf\n",
      "  ✓ Created: CAL_LID_L3_Tropospheric_APro_AllSky-Standard-V4-20.2019-02N.h5\n",
      "\n",
      "Step 2: Converting HDF5 to text...\n",
      "Converted CAL_LID_L3_Tropospheric_APro_AllSky-Standard-V4-20.2019-02N.h5 to CAL_LID_L3_Tropospheric_APro_AllSky-Standard-V4-20.2019-02N.txt\n",
      "Output contains 1272960 points\n",
      "  ✓ Created: CAL_LID_L3_Tropospheric_APro_AllSky-Standard-V4-20.2019-02N.txt\n",
      "✓ Converted: CAL_LID_L3_Tropospheric_APro_AllSky-Standard-V4-20.2019-02N.hdf\n",
      "\n",
      "Summary:\n",
      "- Successful: 9\n",
      "- Failed: 0\n"
     ]
    }
   ],
   "source": [
    "from concurrent.futures import ProcessPoolExecutor, as_completed\n",
    "\n",
    "def batch_convert_calipso(directory, variable_name, pattern=\"*.hdf\", max_workers=4):\n",
    "    \"\"\"\n",
    "    Convert all HDF4 files in a directory to text format.\n",
    "    \"\"\"\n",
    "    directory = Path(directory)\n",
    "    hdf4_files = list(directory.glob(pattern))\n",
    "    \n",
    "    print(f\"Found {len(hdf4_files)} HDF4 files to process\")\n",
    "    \n",
    "    results = []\n",
    "    failed = []\n",
    "    \n",
    "    with ProcessPoolExecutor(max_workers=max_workers) as executor:\n",
    "        # Submit all conversions\n",
    "        future_to_file = {\n",
    "            executor.submit(h4_to_txt, f, variable_name=variable_name): f \n",
    "            for f in hdf4_files\n",
    "        }\n",
    "        \n",
    "        # Process completed conversions\n",
    "        for future in as_completed(future_to_file):\n",
    "            file = future_to_file[future]\n",
    "            try:\n",
    "                txt_file, h5_file = future.result()\n",
    "                results.append((file, txt_file))\n",
    "                print(f\"✓ Converted: {file.name}\")\n",
    "            except Exception as e:\n",
    "                failed.append((file, str(e)))\n",
    "                print(f\"✗ Failed: {file.name} - {e}\")\n",
    "    \n",
    "    print(f\"\\nSummary:\")\n",
    "    print(f\"- Successful: {len(results)}\")\n",
    "    print(f\"- Failed: {len(failed)}\")\n",
    "    \n",
    "    return results, failed\n",
    "\n",
    "# Example usage (uncomment to run)\n",
    "results, failed = batch_convert_calipso(\".\", \"Extinction_Coefficient_532_Mean\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps: PDAL Pipeline\n",
    "\n",
    "After creating text files, you can use PDAL to create point clouds:\n",
    "\n",
    "```bash\n",
    "# Text → LAS\n",
    "pdal pipeline h5tolas.json --readers.text.filename=output.txt --writers.las.filename=output.las\n",
    "\n",
    "# LAS → COPC\n",
    "pdal pipeline las2copc.json --readers.las.filename=output.las --writers.copc.filename=output.copc.las\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "calipso-tool-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
