{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CALIPSO HDF4 to HDF5 Conversion Demo\n",
    "\n",
    "This notebook demonstrates the conversion of CALIPSO HDF4 files to HDF5 format using the `calipso_tool` package.\n",
    "\n",
    "Also prints the variables that are within the file for later selection.\n",
    "\n",
    "[DATA SOURCE](https://asdc.larc.nasa.gov/project/CALIPSO/CAL_LID_L3_Tropospheric_APro_AllSky-Standard-V4-20_V4-20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "from pathlib import Path\n",
    "import h5py\n",
    "import numpy as np\n",
    "from calipso_tool.converter import h4_to_h5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input file found: CAL_LID_L3_Tropospheric_APro_AllSky-Standard-V4-20.2018-12D.hdf\n"
     ]
    }
   ],
   "source": [
    "# Define input and output paths\n",
    "input_file = Path(\"CAL_LID_L3_Tropospheric_APro_AllSky-Standard-V4-20.2018-12D.hdf\")\n",
    "output_file = input_file.with_suffix(\".h5\")\n",
    "\n",
    "# Check if input file exists\n",
    "if input_file.exists():\n",
    "    print(f\"Input file found: {input_file}\")\n",
    "else:\n",
    "    print(f\"Input file not found: {input_file}\")\n",
    "    print(\"Please ensure the HDF4 file is in the current directory\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting CAL_LID_L3_Tropospheric_APro_AllSky-Standard-V4-20.2018-12D.hdf to HDF5 format...\n",
      "Conversion successful! Output file: CAL_LID_L3_Tropospheric_APro_AllSky-Standard-V4-20.2018-12D.h5\n"
     ]
    }
   ],
   "source": [
    "# Perform the HDF4 to HDF5 conversion\n",
    "try:\n",
    "    print(f\"Converting {input_file} to HDF5 format...\")\n",
    "    result = h4_to_h5(input_file, output_file)\n",
    "    print(f\"Conversion successful! Output file: {result}\")\n",
    "except Exception as e:\n",
    "    print(f\"Conversion failed: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HDF5 file structure:\n",
      "==================================================\n",
      "AOD_63_Percent_Below - Dataset (85, 72) >f4\n",
      "AOD_90_Percent_Below - Dataset (85, 72) >f4\n",
      "AOD_Mean - Dataset (85, 72) >f4\n",
      "AOD_Mean_Dust - Dataset (85, 72) >f4\n",
      "AOD_Mean_Elevated_Smoke - Dataset (85, 72) >f4\n",
      "AOD_Mean_Polluted_Dust - Dataset (85, 72) >f4\n",
      "Aerosol_Type - Dataset (85, 72, 208, 7) >i2\n",
      "Altitude_Midpoint - Dataset (1, 208) >f4\n",
      "Days_Of_Month_Observed - Dataset (85, 72) >u4\n",
      "Extinction_Coefficient_532_Mean - Dataset (85, 72, 208) >f4\n",
      "Extinction_Coefficient_532_Mean_Dust - Dataset (85, 72, 208) >f4\n",
      "Extinction_Coefficient_532_Mean_Elevated_Smoke - Dataset (85, 72, 208) >f4\n",
      "Extinction_Coefficient_532_Mean_Polluted_Dust - Dataset (85, 72, 208) >f4\n",
      "Extinction_Coefficient_532_Percentiles - Dataset (85, 72, 208, 11) >f4\n",
      "Extinction_Coefficient_532_Standard_Deviation - Dataset (85, 72, 208) >f4\n",
      "Extinction_Coefficient_532_Standard_Deviation_Dust - Dataset (85, 72, 208) >f4\n",
      "Extinction_Coefficient_532_Standard_Deviation_Elevated_Smoke - Dataset (85, 72, 208) >f4\n",
      "Extinction_Coefficient_532_Standard_Deviation_Polluted_Dust - Dataset (85, 72, 208) >f4\n",
      "Highest_Aerosol_Layer_Detected - Dataset (85, 72, 11) >f4\n",
      "Highest_Aerosol_Layer_Detected_Dust - Dataset (85, 72, 11) >f4\n",
      "Highest_Aerosol_Layer_Detected_Elevated_Smoke - Dataset (85, 72, 11) >f4\n",
      "Highest_Aerosol_Layer_Detected_Polluted_Dust - Dataset (85, 72, 11) >f4\n",
      "Initial_Aerosol_Lidar_Ratio_532 - Dataset (1, 7) >f4\n",
      "Initial_Aerosol_Lidar_Ratio_Uncertainty_532 - Dataset (1, 7) >f4\n",
      "Land_Samples - Dataset (85, 72) >i2\n",
      "Latitude_Midpoint - Dataset (1, 85) >f4\n",
      "Layer_Separation_Maximum - Dataset (85, 72, 7) >f4\n",
      "Layer_Separation_Maximum_Dust - Dataset (85, 72, 7) >f4\n",
      "Layer_Separation_Maximum_Elevated_Smoke - Dataset (85, 72, 7) >f4\n",
      "Layer_Separation_Maximum_Polluted_Dust - Dataset (85, 72, 7) >f4\n",
      "Layer_Separation_Mean - Dataset (85, 72, 7) >f4\n",
      "Layer_Separation_Mean_Dust - Dataset (85, 72, 7) >f4\n",
      "Layer_Separation_Mean_Elevated_Smoke - Dataset (85, 72, 7) >f4\n",
      "Layer_Separation_Mean_Polluted_Dust - Dataset (85, 72, 7) >f4\n",
      "Layer_Separation_Median - Dataset (85, 72, 7) >f4\n",
      "Layer_Separation_Median_Dust - Dataset (85, 72, 7) >f4\n",
      "Layer_Separation_Median_Elevated_Smoke - Dataset (85, 72, 7) >f4\n",
      "Layer_Separation_Median_Polluted_Dust - Dataset (85, 72, 7) >f4\n",
      "Layer_Separation_Minimum - Dataset (85, 72, 7) >f4\n",
      "Layer_Separation_Minimum_Dust - Dataset (85, 72, 7) >f4\n",
      "Layer_Separation_Minimum_Elevated_Smoke - Dataset (85, 72, 7) >f4\n",
      "Layer_Separation_Minimum_Polluted_Dust - Dataset (85, 72, 7) >f4\n",
      "Layer_Separation_Standard_Deviation - Dataset (85, 72, 7) >f4\n",
      "Layer_Separation_Standard_Deviation_Dust - Dataset (85, 72, 7) >f4\n",
      "Layer_Separation_Standard_Deviation_Elevated_Smoke - Dataset (85, 72, 7) >f4\n",
      "Layer_Separation_Standard_Deviation_Polluted_Dust - Dataset (85, 72, 7) >f4\n",
      "Longitude_Midpoint - Dataset (1, 72) >f4\n",
      "Lowest_Aerosol_Layer_Detected - Dataset (85, 72, 11) >f4\n",
      "Lowest_Aerosol_Layer_Detected_Dust - Dataset (85, 72, 11) >f4\n",
      "Lowest_Aerosol_Layer_Detected_Elevated_Smoke - Dataset (85, 72, 11) >f4\n",
      "Lowest_Aerosol_Layer_Detected_Polluted_Dust - Dataset (85, 72, 11) >f4\n",
      "Meteorological_Profiles_Averaged - Dataset (85, 72) >i2\n",
      "Multiple_Aerosol_Type_Count - Dataset (85, 72, 8) >i2\n",
      "Number_Layers_Per_Column - Dataset (85, 72, 9) >i2\n",
      "Number_Layers_Per_Column_Dust - Dataset (85, 72, 9) >i2\n",
      "Number_Layers_Per_Column_Elevated_Smoke - Dataset (85, 72, 9) >i2\n",
      "Number_Layers_Per_Column_Polluted_Dust - Dataset (85, 72, 9) >i2\n",
      "Pressure_Mean - Dataset (85, 72, 208) >f4\n",
      "Pressure_Standard_Deviation - Dataset (85, 72, 208) >f4\n",
      "Relative_Humidity_Mean - Dataset (85, 72, 208) >f4\n",
      "Relative_Humidity_Standard_Deviation - Dataset (85, 72, 208) >f4\n",
      "Samples_Aerosol_Detected_Accepted - Dataset (85, 72, 208) >i2\n",
      "Samples_Aerosol_Detected_Accepted_Dust - Dataset (85, 72, 208) >i2\n",
      "Samples_Aerosol_Detected_Accepted_Elevated_Smoke - Dataset (85, 72, 208) >i2\n",
      "Samples_Aerosol_Detected_Accepted_Polluted_Dust - Dataset (85, 72, 208) >i2\n",
      "Samples_Aerosol_Detected_Rejected - Dataset (85, 72, 208) >i2\n",
      "Samples_Aerosol_Detected_Rejected_Dust - Dataset (85, 72, 208) >i2\n",
      "Samples_Aerosol_Detected_Rejected_Elevated_Smoke - Dataset (85, 72, 208) >i2\n",
      "Samples_Aerosol_Detected_Rejected_Polluted_Dust - Dataset (85, 72, 208) >i2\n",
      "Samples_Averaged - Dataset (85, 72, 208) >i2\n",
      "Samples_Averaged_Dust - Dataset (85, 72, 208) >i2\n",
      "Samples_Averaged_Elevated_Smoke - Dataset (85, 72, 208) >i2\n",
      "Samples_Averaged_Polluted_Dust - Dataset (85, 72, 208) >i2\n",
      "Samples_Cloud_Detected - Dataset (85, 72, 208) >i2\n",
      "Samples_Searched - Dataset (85, 72, 208) >i2\n",
      "Surface_Elevation_Maximum - Dataset (85, 72) >f4\n",
      "Surface_Elevation_Median - Dataset (85, 72) >f4\n",
      "Surface_Elevation_Minimum - Dataset (85, 72) >f4\n",
      "Temperature_Mean - Dataset (85, 72, 208) >f4\n",
      "Temperature_Standard_Deviation - Dataset (85, 72, 208) >f4\n",
      "Tropopause_Height_Maximum - Dataset (85, 72) >f4\n",
      "Tropopause_Height_Mean - Dataset (85, 72) >f4\n",
      "Tropopause_Height_Median - Dataset (85, 72) >f4\n",
      "Tropopause_Height_Minimum - Dataset (85, 72) >f4\n",
      "Tropopause_Height_Standard_Deviation - Dataset (85, 72) >f4\n",
      "Water_Samples - Dataset (85, 72) >i2\n",
      "fakeDim0 - Dataset (1,) int32\n",
      "fakeDim1 - Dataset (72,) int32\n",
      "fakeDim140 - Dataset (8,) int32\n",
      "fakeDim143 - Dataset (9,) int32\n",
      "fakeDim3 - Dataset (85,) int32\n",
      "fakeDim49 - Dataset (7,) int32\n",
      "fakeDim5 - Dataset (208,) int32\n",
      "fakeDim61 - Dataset (11,) int32\n",
      "metadata - Dataset (1,) [('Product_ID', 'S80'), ('Nominal_Year_Month', 'S6'), ('Number_of_Level2_Files_Analyzed', '>u2'), ('Earliest_Input_Filename', 'S160'), ('Latest_Input_Filename', 'S160'), ('Data_Screening_Script_Filename', 'S160'), ('Data_Screening_Script_File_Contents', 'S5000'), ('List_of_Input_Files', 'S30000')]\n"
     ]
    }
   ],
   "source": [
    "# Verify the conversion by reading the HDF5 file\n",
    "if output_file.exists():\n",
    "    with h5py.File(output_file, 'r') as f:\n",
    "        print(\"HDF5 file structure:\")\n",
    "        print(\"=\"*50)\n",
    "        \n",
    "        def print_structure(name, obj):\n",
    "            indent = name.count('/') * '  '\n",
    "            if isinstance(obj, h5py.Dataset):\n",
    "                print(f\"{indent}{name.split('/')[-1]} - Dataset {obj.shape} {obj.dtype}\")\n",
    "            elif isinstance(obj, h5py.Group):\n",
    "                print(f\"{indent}{name.split('/')[-1]}/\")\n",
    "        \n",
    "        f.visititems(print_structure)\n",
    "else:\n",
    "    print(\"Output file not found. Conversion may have failed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-level groups:\n",
      "  - metadata_t\n",
      "  - metadata\n",
      "  - Longitude_Midpoint\n",
      "  - fakeDim0\n",
      "  - fakeDim1\n",
      "  - Latitude_Midpoint\n",
      "  - fakeDim3\n",
      "  - Altitude_Midpoint\n",
      "  - fakeDim5\n",
      "  - Pressure_Mean\n",
      "  - Pressure_Standard_Deviation\n",
      "  - Temperature_Mean\n",
      "  - Temperature_Standard_Deviation\n",
      "  - Relative_Humidity_Mean\n",
      "  - Relative_Humidity_Standard_Deviation\n",
      "  - Tropopause_Height_Minimum\n",
      "  - Tropopause_Height_Maximum\n",
      "  - Tropopause_Height_Median\n",
      "  - Tropopause_Height_Mean\n",
      "  - Tropopause_Height_Standard_Deviation\n",
      "  - Meteorological_Profiles_Averaged\n",
      "  - Surface_Elevation_Minimum\n",
      "  - Surface_Elevation_Maximum\n",
      "  - Surface_Elevation_Median\n",
      "  - Land_Samples\n",
      "  - Water_Samples\n",
      "  - Days_Of_Month_Observed\n",
      "  - Initial_Aerosol_Lidar_Ratio_532\n",
      "  - fakeDim49\n",
      "  - Initial_Aerosol_Lidar_Ratio_Uncertainty_532\n",
      "  - Extinction_Coefficient_532_Mean\n",
      "  - Extinction_Coefficient_532_Standard_Deviation\n",
      "  - Extinction_Coefficient_532_Percentiles\n",
      "  - fakeDim61\n",
      "  - Samples_Searched\n",
      "  - Samples_Aerosol_Detected_Accepted\n",
      "  - Samples_Aerosol_Detected_Rejected\n",
      "  - Samples_Cloud_Detected\n",
      "  - Samples_Averaged\n",
      "  - AOD_Mean\n",
      "  - AOD_63_Percent_Below\n",
      "  - AOD_90_Percent_Below\n",
      "  - Extinction_Coefficient_532_Mean_Dust\n",
      "  - Extinction_Coefficient_532_Standard_Deviation_Dust\n",
      "  - Samples_Aerosol_Detected_Accepted_Dust\n",
      "  - Samples_Aerosol_Detected_Rejected_Dust\n",
      "  - Samples_Averaged_Dust\n",
      "  - AOD_Mean_Dust\n",
      "  - Extinction_Coefficient_532_Mean_Elevated_Smoke\n",
      "  - Extinction_Coefficient_532_Standard_Deviation_Elevated_Smoke\n",
      "  - Samples_Aerosol_Detected_Accepted_Elevated_Smoke\n",
      "  - Samples_Aerosol_Detected_Rejected_Elevated_Smoke\n",
      "  - Samples_Averaged_Elevated_Smoke\n",
      "  - AOD_Mean_Elevated_Smoke\n",
      "  - Extinction_Coefficient_532_Mean_Polluted_Dust\n",
      "  - Extinction_Coefficient_532_Standard_Deviation_Polluted_Dust\n",
      "  - Samples_Aerosol_Detected_Accepted_Polluted_Dust\n",
      "  - Samples_Aerosol_Detected_Rejected_Polluted_Dust\n",
      "  - Samples_Averaged_Polluted_Dust\n",
      "  - AOD_Mean_Polluted_Dust\n",
      "  - Aerosol_Type\n",
      "  - Multiple_Aerosol_Type_Count\n",
      "  - fakeDim140\n",
      "  - Number_Layers_Per_Column\n",
      "  - fakeDim143\n",
      "  - Highest_Aerosol_Layer_Detected\n",
      "  - Lowest_Aerosol_Layer_Detected\n",
      "  - Layer_Separation_Minimum\n",
      "  - Layer_Separation_Maximum\n",
      "  - Layer_Separation_Median\n",
      "  - Layer_Separation_Mean\n",
      "  - Layer_Separation_Standard_Deviation\n",
      "  - Number_Layers_Per_Column_Dust\n",
      "  - Highest_Aerosol_Layer_Detected_Dust\n",
      "  - Lowest_Aerosol_Layer_Detected_Dust\n",
      "  - Layer_Separation_Minimum_Dust\n",
      "  - Layer_Separation_Maximum_Dust\n",
      "  - Layer_Separation_Median_Dust\n",
      "  - Layer_Separation_Mean_Dust\n",
      "  - Layer_Separation_Standard_Deviation_Dust\n",
      "  - Number_Layers_Per_Column_Elevated_Smoke\n",
      "  - Highest_Aerosol_Layer_Detected_Elevated_Smoke\n",
      "  - Lowest_Aerosol_Layer_Detected_Elevated_Smoke\n",
      "  - Layer_Separation_Minimum_Elevated_Smoke\n",
      "  - Layer_Separation_Maximum_Elevated_Smoke\n",
      "  - Layer_Separation_Median_Elevated_Smoke\n",
      "  - Layer_Separation_Mean_Elevated_Smoke\n",
      "  - Layer_Separation_Standard_Deviation_Elevated_Smoke\n",
      "  - Number_Layers_Per_Column_Polluted_Dust\n",
      "  - Highest_Aerosol_Layer_Detected_Polluted_Dust\n",
      "  - Lowest_Aerosol_Layer_Detected_Polluted_Dust\n",
      "  - Layer_Separation_Minimum_Polluted_Dust\n",
      "  - Layer_Separation_Maximum_Polluted_Dust\n",
      "  - Layer_Separation_Median_Polluted_Dust\n",
      "  - Layer_Separation_Mean_Polluted_Dust\n",
      "  - Layer_Separation_Standard_Deviation_Polluted_Dust\n"
     ]
    }
   ],
   "source": [
    "# Explore specific datasets in the HDF5 file\n",
    "if output_file.exists():\n",
    "    with h5py.File(output_file, 'r') as f:\n",
    "        # List all top-level groups\n",
    "        print(\"Top-level groups:\")\n",
    "        for key in f.keys():\n",
    "            print(f\"  - {key}\")\n",
    "        \n",
    "        # Example: Access a specific dataset (adjust path as needed)\n",
    "        # This will depend on the actual structure of your CALIPSO file\n",
    "        # Common CALIPSO variables might include:\n",
    "        # - Extinction_Coefficient_532\n",
    "        # - Temperature\n",
    "        # - Pressure\n",
    "        # - Latitude\n",
    "        # - Longitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File attributes:\n",
      "  coremetadata: b'\\nGROUP                  = INVENTORYMETADATA\\n  GROUPTYPE            = MASTERGROUP\\n\\n  GROUP                  = GRANULE\\n\\n    OBJECT                 = GRANULEID\\n      NUM_VAL              = 1\\n      VALUE                = \"CAL_LID_L3_Tropospheric_APro_AllSky\"\\n    END_OBJECT             = GRANULEID\\n\\n    OBJECT                 = GRANULENAME\\n      NUM_VAL              = 1\\n      VALUE                = \"CAL_LID_L3_Tropospheric_APro_AllSky-Standard-V4-20.2018-12D.hdf\"\\n    END_OBJECT             = GRANULENAME\\n\\n    OBJECT                 = GRANULEVERSION\\n      NUM_VAL              = 1\\n      VALUE                = \"V4-20\"\\n    END_OBJECT             = GRANULEVERSION\\n\\n    OBJECT                 = DAYNIGHT\\n      NUM_VAL              = 1\\n      VALUE                = \"D\"\\n    END_OBJECT             = DAYNIGHT\\n\\n    OBJECT                 = BROWSE\\n      NUM_VAL              = 1\\n      VALUE                = \"N\"\\n    END_OBJECT             = BROWSE\\n\\n    OBJECT                 = GRINGTYPE\\n      NUM_VAL              = 1\\n      VALUE                = \"R\"\\n    END_OBJECT             = GRINGTYPE\\n\\n  END_GROUP              = GRANULE\\n\\n  GROUP                  = METADATA\\n\\n    OBJECT                 = METADATANAME\\n      NUM_VAL              = 1\\n      VALUE                = \"CAL_LID_L3_Tropospheric_APro_AllSky-Standard-V4-20.2018-12D.hdf.met\"\\n    END_OBJECT             = METADATANAME\\n\\n  END_GROUP              = METADATA\\n\\n  GROUP                  = TEMPORALINFORMATION\\n\\n    OBJECT                 = PRODUCTIONDATETIME\\n      NUM_VAL              = 1\\n      VALUE                = \"2019-09-09T17:36:55Z\"\\n    END_OBJECT             = PRODUCTIONDATETIME\\n\\n    OBJECT                 = START_DATE\\n      NUM_VAL              = 1\\n      VALUE                = \"2018-12-01T00:00:00Z\"\\n    END_OBJECT             = START_DATE\\n\\n    OBJECT                 = STOP_DATE\\n      NUM_VAL              = 1\\n      VALUE                = \"2019-01-01T00:00:00Z\"\\n    END_OBJECT             = STOP_DATE\\n\\n  END_GROUP              = TEMPORALINFORMATION\\n\\n  GROUP                  = QA\\n\\n    OBJECT                 = QAFLAG\\n      NUM_VAL              = 1\\n      VALUE                = \"Passed\"\\n    END_OBJECT             = QAFLAG\\n\\n    OBJECT                 = QAEXPLANATION\\n      NUM_VAL              = 1\\n      VALUE                = \"All data passed during checkout\"\\n    END_OBJECT             = QAEXPLANATION\\n\\n  END_GROUP              = QA\\n\\n  GROUP                  = GEOMINMAX\\n\\n    OBJECT                 = MINLAT\\n      NUM_VAL              = 1\\n      VALUE                = -90.0\\n    END_OBJECT             = MINLAT\\n\\n    OBJECT                 = MINLON\\n      NUM_VAL              = 1\\n      VALUE                = -180.0\\n    END_OBJECT             = MINLON\\n\\n    OBJECT                 = MAXLAT\\n      NUM_VAL              = 1\\n      VALUE                = 90.0\\n    END_OBJECT             = MAXLAT\\n\\n    OBJECT                 = MAXLON\\n      NUM_VAL              = 1\\n      VALUE                = 180.0\\n    END_OBJECT             = MAXLON\\n\\n  END_GROUP              = GEOMINMAX\\n\\n  GROUP                  = GRING\\n\\n    OBJECT                 = GRINGCONTAINER\\n      CLASS                = \"1\"\\n\\n      OBJECT                 = GRINGLATITUDE\\n        CLASS                = \"1\"\\n        NUM_VAL              = 21\\n        VALUE                = (90.0, 45.0, 0.0, -45.0, -90.0, -90.0, -90.0, -90.0, -90.0, -90.0, -90.0, -45.0, 0.0, 45.0, 90.0, 90.0, 90.0, 90.0, 90.0, 90.0, 90.0)\\n      END_OBJECT             = GRINGLATITUDE\\n\\n      OBJECT                 = GRINGLONGITUDE\\n        CLASS                = \"1\"\\n        NUM_VAL              = 21\\n        VALUE                = (-180.0, -180.0, -180.0, -180.0, -180.0, -120.0, -60.0, 0.0, 60.0, 120.0, 180.0, 180.0, 180.0, 180.0, 180.0, 120.0, 60.0, 0.0, -60.0, -120.0, -180.0)\\n      END_OBJECT             = GRINGLONGITUDE\\n\\n    END_OBJECT             = GRINGCONTAINER\\n\\n  END_GROUP              = GRING\\n\\n  GROUP                  = ORBITPATH\\n\\n    OBJECT                 = STARTORBITNUMBER\\n      NUM_VAL              = 1\\n      VALUE                = -999\\n    END_OBJECT             = STARTORBITNUMBER\\n\\n    OBJECT                 = STOPORBITNUMBER\\n      NUM_VAL              = 1\\n      VALUE                = -999\\n    END_OBJECT             = STOPORBITNUMBER\\n\\n    OBJECT                 = ORBITCHANGETIME\\n      NUM_VAL              = 1\\n      VALUE                = -999.0\\n    END_OBJECT             = ORBITCHANGETIME\\n\\n    OBJECT                 = STARTPATHNUMBER\\n      NUM_VAL              = 1\\n      VALUE                = -999\\n    END_OBJECT             = STARTPATHNUMBER\\n\\n    OBJECT                 = STOPPATHNUMBER\\n      NUM_VAL              = 1\\n      VALUE                = -999\\n    END_OBJECT             = STOPPATHNUMBER\\n\\n    OBJECT                 = PATHCHANGETIME\\n      NUM_VAL              = 1\\n      VALUE                = -999.0\\n    END_OBJECT             = PATHCHANGETIME\\n\\n  END_GROUP              = ORBITPATH\\n\\nEND_GROUP              = INVENTORYMETADATA\\n\\nEND\\n'\n",
      "  archivemetadata: b'\\nGROUP                  = ARCHIVEDMETADATA\\n  GROUPTYPE            = MASTERGROUP\\n\\n  OBJECT                 = NUMBEROFRECORDS\\n    NUM_VAL              = 1\\n    VALUE                = -1\\n  END_OBJECT             = NUMBEROFRECORDS\\n\\nEND_GROUP              = ARCHIVEDMETADATA\\n\\nEND\\n'\n"
     ]
    }
   ],
   "source": [
    "# Example: Read and display metadata\n",
    "if output_file.exists():\n",
    "    with h5py.File(output_file, 'r') as f:\n",
    "        print(\"File attributes:\")\n",
    "        for attr in f.attrs:\n",
    "            print(f\"  {attr}: {f.attrs[attr]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "After converting to HDF5, you can:\n",
    "\n",
    "1. Export specific variables to ASCII format\n",
    "2. Convert to LAS format using PDAL\n",
    "3. Create Cloud-Optimized Point Clouds (COPC)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "calipso-tool-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
