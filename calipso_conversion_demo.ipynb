{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CALIPSO HDF4 to HDF5 Conversion Demo\n",
    "\n",
    "This notebook demonstrates the conversion of CALIPSO HDF4 files to HDF5 format using the `calipso_tool` package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "from pathlib import Path\n",
    "import h5py\n",
    "import numpy as np\n",
    "from calipso_tool.converter import h4_to_h5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define input and output paths\n",
    "input_file = Path(\"CAL_LID_L3_Tropospheric_APro_AllSky-Standard-V4-20.2018-12D.hdf\")\n",
    "output_file = Path(\"CAL_LID_L3_Tropospheric_APro_AllSky-Standard-V4-20.2018-12D.h5\")\n",
    "\n",
    "# Check if input file exists\n",
    "if input_file.exists():\n",
    "    print(f\"Input file found: {input_file}\")\n",
    "else:\n",
    "    print(f\"Input file not found: {input_file}\")\n",
    "    print(\"Please ensure the HDF4 file is in the current directory\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform the HDF4 to HDF5 conversion\n",
    "try:\n",
    "    print(f\"Converting {input_file} to HDF5 format...\")\n",
    "    result = h4_to_h5(input_file, output_file)\n",
    "    print(f\"Conversion successful! Output file: {result}\")\n",
    "except Exception as e:\n",
    "    print(f\"Conversion failed: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify the conversion by reading the HDF5 file\n",
    "if output_file.exists():\n",
    "    with h5py.File(output_file, 'r') as f:\n",
    "        print(\"HDF5 file structure:\")\n",
    "        print(\"=\"*50)\n",
    "        \n",
    "        def print_structure(name, obj):\n",
    "            indent = name.count('/') * '  '\n",
    "            if isinstance(obj, h5py.Dataset):\n",
    "                print(f\"{indent}{name.split('/')[-1]} - Dataset {obj.shape} {obj.dtype}\")\n",
    "            elif isinstance(obj, h5py.Group):\n",
    "                print(f\"{indent}{name.split('/')[-1]}/\")\n",
    "        \n",
    "        f.visititems(print_structure)\n",
    "else:\n",
    "    print(\"Output file not found. Conversion may have failed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore specific datasets in the HDF5 file\n",
    "if output_file.exists():\n",
    "    with h5py.File(output_file, 'r') as f:\n",
    "        # List all top-level groups\n",
    "        print(\"Top-level groups:\")\n",
    "        for key in f.keys():\n",
    "            print(f\"  - {key}\")\n",
    "        \n",
    "        # Example: Access a specific dataset (adjust path as needed)\n",
    "        # This will depend on the actual structure of your CALIPSO file\n",
    "        # Common CALIPSO variables might include:\n",
    "        # - Extinction_Coefficient_532\n",
    "        # - Temperature\n",
    "        # - Pressure\n",
    "        # - Latitude\n",
    "        # - Longitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Read and display metadata\n",
    "if output_file.exists():\n",
    "    with h5py.File(output_file, 'r') as f:\n",
    "        print(\"File attributes:\")\n",
    "        for attr in f.attrs:\n",
    "            print(f\"  {attr}: {f.attrs[attr]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "After converting to HDF5, you can:\n",
    "\n",
    "1. Export specific variables to ASCII format\n",
    "2. Convert to LAS format using PDAL\n",
    "3. Create Cloud-Optimized Point Clouds (COPC)\n",
    "\n",
    "These additional conversion steps can be performed using the PDAL pipelines included with this package:\n",
    "- `h5tolas.json` - Convert HDF5 to LAS\n",
    "- `las2copc.json` - Convert LAS to COPC"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}