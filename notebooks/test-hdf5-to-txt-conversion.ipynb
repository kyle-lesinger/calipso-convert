{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HDF5 to Text Conversion Demo\n",
    "\n",
    "This notebook demonstrates how to convert CALIPSO HDF5 files to space-delimited text format using the `h5_to_txt` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "from pathlib import Path\n",
    "import h5py\n",
    "import pandas as pd\n",
    "from calipso_tool.h5_to_txt import h5_to_txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HDF5 file found: CAL_LID_L3_Tropospheric_APro_AllSky-Standard-V4-21.2020-12D.h5\n"
     ]
    }
   ],
   "source": [
    "# Define the HDF5 file path\n",
    "h5_file = Path(\"CAL_LID_L3_Tropospheric_APro_AllSky-Standard-V4-21.2020-12D.h5\")\n",
    "\n",
    "# Check if the file exists\n",
    "if h5_file.exists():\n",
    "    print(f\"HDF5 file found: {h5_file}\")\n",
    "else:\n",
    "    print(f\"HDF5 file not found: {h5_file}\")\n",
    "    print(\"Please run the HDF4 to HDF5 conversion first.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available datasets in the HDF5 file:\n",
      "==================================================\n",
      "AOD_63_Percent_Below: shape=(85, 72), dtype=>f4\n",
      "AOD_90_Percent_Below: shape=(85, 72), dtype=>f4\n",
      "AOD_Mean: shape=(85, 72), dtype=>f4\n",
      "AOD_Mean_Dust: shape=(85, 72), dtype=>f4\n",
      "AOD_Mean_Elevated_Smoke: shape=(85, 72), dtype=>f4\n",
      "AOD_Mean_Polluted_Dust: shape=(85, 72), dtype=>f4\n",
      "Aerosol_Type: shape=(85, 72, 208, 7), dtype=>i2\n",
      "Altitude_Midpoint: shape=(1, 208), dtype=>f4\n",
      "Days_Of_Month_Observed: shape=(85, 72), dtype=>u4\n",
      "Extinction_Coefficient_532_Mean: shape=(85, 72, 208), dtype=>f4\n",
      "Extinction_Coefficient_532_Mean_Dust: shape=(85, 72, 208), dtype=>f4\n",
      "Extinction_Coefficient_532_Mean_Elevated_Smoke: shape=(85, 72, 208), dtype=>f4\n",
      "Extinction_Coefficient_532_Mean_Polluted_Dust: shape=(85, 72, 208), dtype=>f4\n",
      "Extinction_Coefficient_532_Percentiles: shape=(85, 72, 208, 11), dtype=>f4\n",
      "Extinction_Coefficient_532_Standard_Deviation: shape=(85, 72, 208), dtype=>f4\n",
      "Extinction_Coefficient_532_Standard_Deviation_Dust: shape=(85, 72, 208), dtype=>f4\n",
      "Extinction_Coefficient_532_Standard_Deviation_Elevated_Smoke: shape=(85, 72, 208), dtype=>f4\n",
      "Extinction_Coefficient_532_Standard_Deviation_Polluted_Dust: shape=(85, 72, 208), dtype=>f4\n",
      "Highest_Aerosol_Layer_Detected: shape=(85, 72, 11), dtype=>f4\n",
      "Highest_Aerosol_Layer_Detected_Dust: shape=(85, 72, 11), dtype=>f4\n",
      "Highest_Aerosol_Layer_Detected_Elevated_Smoke: shape=(85, 72, 11), dtype=>f4\n",
      "Highest_Aerosol_Layer_Detected_Polluted_Dust: shape=(85, 72, 11), dtype=>f4\n",
      "Initial_Aerosol_Lidar_Ratio_532: shape=(1, 7), dtype=>f4\n",
      "Initial_Aerosol_Lidar_Ratio_Uncertainty_532: shape=(1, 7), dtype=>f4\n",
      "Land_Samples: shape=(85, 72), dtype=>i2\n",
      "Latitude_Midpoint: shape=(1, 85), dtype=>f4\n",
      "Layer_Separation_Maximum: shape=(85, 72, 7), dtype=>f4\n",
      "Layer_Separation_Maximum_Dust: shape=(85, 72, 7), dtype=>f4\n",
      "Layer_Separation_Maximum_Elevated_Smoke: shape=(85, 72, 7), dtype=>f4\n",
      "Layer_Separation_Maximum_Polluted_Dust: shape=(85, 72, 7), dtype=>f4\n",
      "Layer_Separation_Mean: shape=(85, 72, 7), dtype=>f4\n",
      "Layer_Separation_Mean_Dust: shape=(85, 72, 7), dtype=>f4\n",
      "Layer_Separation_Mean_Elevated_Smoke: shape=(85, 72, 7), dtype=>f4\n",
      "Layer_Separation_Mean_Polluted_Dust: shape=(85, 72, 7), dtype=>f4\n",
      "Layer_Separation_Median: shape=(85, 72, 7), dtype=>f4\n",
      "Layer_Separation_Median_Dust: shape=(85, 72, 7), dtype=>f4\n",
      "Layer_Separation_Median_Elevated_Smoke: shape=(85, 72, 7), dtype=>f4\n",
      "Layer_Separation_Median_Polluted_Dust: shape=(85, 72, 7), dtype=>f4\n",
      "Layer_Separation_Minimum: shape=(85, 72, 7), dtype=>f4\n",
      "Layer_Separation_Minimum_Dust: shape=(85, 72, 7), dtype=>f4\n",
      "Layer_Separation_Minimum_Elevated_Smoke: shape=(85, 72, 7), dtype=>f4\n",
      "Layer_Separation_Minimum_Polluted_Dust: shape=(85, 72, 7), dtype=>f4\n",
      "Layer_Separation_Standard_Deviation: shape=(85, 72, 7), dtype=>f4\n",
      "Layer_Separation_Standard_Deviation_Dust: shape=(85, 72, 7), dtype=>f4\n",
      "Layer_Separation_Standard_Deviation_Elevated_Smoke: shape=(85, 72, 7), dtype=>f4\n",
      "Layer_Separation_Standard_Deviation_Polluted_Dust: shape=(85, 72, 7), dtype=>f4\n",
      "Longitude_Midpoint: shape=(1, 72), dtype=>f4\n",
      "Lowest_Aerosol_Layer_Detected: shape=(85, 72, 11), dtype=>f4\n",
      "Lowest_Aerosol_Layer_Detected_Dust: shape=(85, 72, 11), dtype=>f4\n",
      "Lowest_Aerosol_Layer_Detected_Elevated_Smoke: shape=(85, 72, 11), dtype=>f4\n",
      "Lowest_Aerosol_Layer_Detected_Polluted_Dust: shape=(85, 72, 11), dtype=>f4\n",
      "Meteorological_Profiles_Averaged: shape=(85, 72), dtype=>i2\n",
      "Multiple_Aerosol_Type_Count: shape=(85, 72, 8), dtype=>i2\n",
      "Number_Layers_Per_Column: shape=(85, 72, 9), dtype=>i2\n",
      "Number_Layers_Per_Column_Dust: shape=(85, 72, 9), dtype=>i2\n",
      "Number_Layers_Per_Column_Elevated_Smoke: shape=(85, 72, 9), dtype=>i2\n",
      "Number_Layers_Per_Column_Polluted_Dust: shape=(85, 72, 9), dtype=>i2\n",
      "Pressure_Mean: shape=(85, 72, 208), dtype=>f4\n",
      "Pressure_Standard_Deviation: shape=(85, 72, 208), dtype=>f4\n",
      "Relative_Humidity_Mean: shape=(85, 72, 208), dtype=>f4\n",
      "Relative_Humidity_Standard_Deviation: shape=(85, 72, 208), dtype=>f4\n",
      "Samples_Aerosol_Detected_Accepted: shape=(85, 72, 208), dtype=>i2\n",
      "Samples_Aerosol_Detected_Accepted_Dust: shape=(85, 72, 208), dtype=>i2\n",
      "Samples_Aerosol_Detected_Accepted_Elevated_Smoke: shape=(85, 72, 208), dtype=>i2\n",
      "Samples_Aerosol_Detected_Accepted_Polluted_Dust: shape=(85, 72, 208), dtype=>i2\n",
      "Samples_Aerosol_Detected_Rejected: shape=(85, 72, 208), dtype=>i2\n",
      "Samples_Aerosol_Detected_Rejected_Dust: shape=(85, 72, 208), dtype=>i2\n",
      "Samples_Aerosol_Detected_Rejected_Elevated_Smoke: shape=(85, 72, 208), dtype=>i2\n",
      "Samples_Aerosol_Detected_Rejected_Polluted_Dust: shape=(85, 72, 208), dtype=>i2\n",
      "Samples_Averaged: shape=(85, 72, 208), dtype=>i2\n",
      "Samples_Averaged_Dust: shape=(85, 72, 208), dtype=>i2\n",
      "Samples_Averaged_Elevated_Smoke: shape=(85, 72, 208), dtype=>i2\n",
      "Samples_Averaged_Polluted_Dust: shape=(85, 72, 208), dtype=>i2\n",
      "Samples_Cloud_Detected: shape=(85, 72, 208), dtype=>i2\n",
      "Samples_Searched: shape=(85, 72, 208), dtype=>i2\n",
      "Surface_Elevation_Maximum: shape=(85, 72), dtype=>f4\n",
      "Surface_Elevation_Median: shape=(85, 72), dtype=>f4\n",
      "Surface_Elevation_Minimum: shape=(85, 72), dtype=>f4\n",
      "Temperature_Mean: shape=(85, 72, 208), dtype=>f4\n",
      "Temperature_Standard_Deviation: shape=(85, 72, 208), dtype=>f4\n",
      "Tropopause_Height_Maximum: shape=(85, 72), dtype=>f4\n",
      "Tropopause_Height_Mean: shape=(85, 72), dtype=>f4\n",
      "Tropopause_Height_Median: shape=(85, 72), dtype=>f4\n",
      "Tropopause_Height_Minimum: shape=(85, 72), dtype=>f4\n",
      "Tropopause_Height_Standard_Deviation: shape=(85, 72), dtype=>f4\n",
      "Water_Samples: shape=(85, 72), dtype=>i2\n",
      "fakeDim0: shape=(1,), dtype=int32\n",
      "fakeDim1: shape=(72,), dtype=int32\n",
      "fakeDim140: shape=(8,), dtype=int32\n",
      "fakeDim143: shape=(9,), dtype=int32\n",
      "fakeDim3: shape=(85,), dtype=int32\n",
      "fakeDim49: shape=(7,), dtype=int32\n",
      "fakeDim5: shape=(208,), dtype=int32\n",
      "fakeDim61: shape=(11,), dtype=int32\n",
      "metadata: shape=(1,), dtype=[('Product_ID', 'S80'), ('Nominal_Year_Month', 'S6'), ('Number_of_Level2_Files_Analyzed', '>u2'), ('Earliest_Input_Filename', 'S160'), ('Latest_Input_Filename', 'S160'), ('Data_Screening_Script_Filename', 'S160'), ('Data_Screening_Script_File_Contents', 'S5000'), ('List_of_Input_Files', 'S30000')]\n"
     ]
    }
   ],
   "source": [
    "# Explore the HDF5 file structure to find available variables\n",
    "if h5_file.exists():\n",
    "    with h5py.File(h5_file, 'r') as f:\n",
    "        print(\"Available datasets in the HDF5 file:\")\n",
    "        print(\"=\" * 50)\n",
    "        \n",
    "        def list_datasets(name, obj):\n",
    "            if isinstance(obj, h5py.Dataset):\n",
    "                print(f\"{name}: shape={obj.shape}, dtype={obj.dtype}\")\n",
    "        \n",
    "        f.visititems(list_datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking for coordinate datasets:\n",
      "✓ Latitude_Midpoint found: shape=(1, 85)\n",
      "✓ Longitude_Midpoint found: shape=(1, 72)\n",
      "✓ Altitude_Midpoint found: shape=(1, 208)\n"
     ]
    }
   ],
   "source": [
    "# Check for required coordinate datasets\n",
    "if h5_file.exists():\n",
    "    with h5py.File(h5_file, 'r') as f:\n",
    "        print(\"Checking for coordinate datasets:\")\n",
    "        required_coords = [\"Latitude_Midpoint\", \"Longitude_Midpoint\", \"Altitude_Midpoint\"]\n",
    "        \n",
    "        for coord in required_coords:\n",
    "            if coord in f:\n",
    "                print(f\"✓ {coord} found: shape={f[coord].shape}\")\n",
    "            else:\n",
    "                print(f\"✗ {coord} NOT found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting CAL_LID_L3_Tropospheric_APro_AllSky-Standard-V4-21.2020-12D.h5 to text format...\n",
      "Extracting variable: Samples_Averaged_Polluted_Dust\n",
      "Converted CAL_LID_L3_Tropospheric_APro_AllSky-Standard-V4-21.2020-12D.h5 to CAL_LID_L3_Tropospheric_APro_AllSky-Standard-V4-21.2020-12D.txt\n",
      "Output contains 1272960 points\n",
      "\n",
      "Conversion successful!\n",
      "Output file: CAL_LID_L3_Tropospheric_APro_AllSky-Standard-V4-21.2020-12D.txt\n"
     ]
    }
   ],
   "source": [
    "# Convert HDF5 to text format\n",
    "# You need to replace 'var_to_grab' with an actual variable name from your HDF5 file\n",
    "# Common CALIPSO variables might include:\n",
    "# - \"Extinction_Coefficient_532\"\n",
    "# - \"Temperature_Met\"\n",
    "# - \"Pressure_Met\"\n",
    "# - \"Samples_Averaged\"\n",
    "\n",
    "variable_name = \"Samples_Averaged_Polluted_Dust\"  # UPDATE THIS with your actual variable name\n",
    "output_txt = h5_file.with_suffix('.txt')\n",
    "\n",
    "try:\n",
    "    print(f\"Converting {h5_file} to text format...\")\n",
    "    print(f\"Extracting variable: {variable_name}\")\n",
    "    \n",
    "    result = h5_to_txt(\n",
    "        input_h5=h5_file,\n",
    "        output_txt=output_txt,\n",
    "        variable_name=variable_name,\n",
    "        altitude_units=\"km\"  # Will convert km to meters\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nConversion successful!\")\n",
    "    print(f\"Output file: {result}\")\n",
    "    \n",
    "except KeyError as e:\n",
    "    print(f\"\\nError: {e}\")\n",
    "    print(\"\\nPlease update the 'variable_name' with one of the available variables from the HDF5 file.\")\n",
    "except Exception as e:\n",
    "    print(f\"\\nConversion failed: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading CAL_LID_L3_Tropospheric_APro_AllSky-Standard-V4-21.2020-12D.txt...\n",
      "\n",
      "First 10 rows:\n",
      "       X     Y           Z  Samples_Averaged_Polluted_Dust\n",
      "0 -177.5 -84.0 -380.048070                             0.0\n",
      "1 -177.5 -84.0 -320.144230                             0.0\n",
      "2 -177.5 -84.0 -260.240400                             0.0\n",
      "3 -177.5 -84.0 -200.336550                             0.0\n",
      "4 -177.5 -84.0 -140.432680                             0.0\n",
      "5 -177.5 -84.0  -80.528830                             0.0\n",
      "6 -177.5 -84.0  -20.625002                             0.0\n",
      "7 -177.5 -84.0   39.278828                             0.0\n",
      "8 -177.5 -84.0   99.182686                             0.0\n",
      "9 -177.5 -84.0  159.086550                             0.0\n",
      "\n",
      "File statistics:\n",
      "Total points: 1,272,960\n",
      "Columns: ['X', 'Y', 'Z', 'Samples_Averaged_Polluted_Dust']\n",
      "\n",
      "Data ranges:\n",
      "  X: [-177.500, 177.500]\n",
      "  Y: [-84.000, 84.000]\n",
      "  Z: [-380.048, 12020.048]\n",
      "  Samples_Averaged_Polluted_Dust: [0.000, 2018.000]\n"
     ]
    }
   ],
   "source": [
    "# Read and display the first few lines of the text file\n",
    "if output_txt.exists():\n",
    "    print(f\"Reading {output_txt}...\\n\")\n",
    "    \n",
    "    # Read with pandas\n",
    "    df = pd.read_csv(output_txt, sep=' ', nrows=10)\n",
    "    print(\"First 10 rows:\")\n",
    "    print(df)\n",
    "    \n",
    "    # Get file statistics\n",
    "    df_full = pd.read_csv(output_txt, sep=' ')\n",
    "    print(f\"\\nFile statistics:\")\n",
    "    print(f\"Total points: {len(df_full):,}\")\n",
    "    print(f\"Columns: {list(df_full.columns)}\")\n",
    "    print(f\"\\nData ranges:\")\n",
    "    for col in df_full.columns:\n",
    "        print(f\"  {col}: [{df_full[col].min():.3f}, {df_full[col].max():.3f}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the Command Line Interface\n",
    "\n",
    "You can also use the `h5_to_txt` module directly from the command line:\n",
    "\n",
    "```bash\n",
    "# Basic usage\n",
    "python -m calipso_tool.h5_to_txt input.h5\n",
    "\n",
    "# Specify output file\n",
    "python -m calipso_tool.h5_to_txt input.h5 -o output.txt\n",
    "\n",
    "# Specify variable name\n",
    "python -m calipso_tool.h5_to_txt input.h5 -v Extinction_Coefficient_532\n",
    "\n",
    "# Specify altitude units (if already in meters)\n",
    "python -m calipso_tool.h5_to_txt input.h5 --alt-units m\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "The generated text file can be used with PDAL pipelines to create LAS files:\n",
    "\n",
    "```bash\n",
    "pdal pipeline h5tolas.json --readers.text.filename=points.txt --writers.las.filename=output.las\n",
    "```\n",
    "\n",
    "And then convert to COPC:\n",
    "\n",
    "```bash\n",
    "pdal pipeline las2copc.json --readers.las.filename=output.las --writers.copc.filename=output.copc.las\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "calipso-tool-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
